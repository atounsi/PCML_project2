{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from helpers import *\n",
    "from plots import *\n",
    "from plots import *\n",
    "from split_data import *\n",
    "from recommender import *\n",
    "from cross_validation import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\u001c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "path_dataset = \"../data/data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 'compiled'\n"
     ]
    }
   ],
   "source": [
    "def split_data(ratings, p_test=0.1, seed=48):\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # generate random indices\n",
    "    row = ratings.shape[0]\n",
    "    col = ratings.shape[1]\n",
    "    num = row*col\n",
    "    \n",
    "    indices = np.random.permutation(num)\n",
    "    index_split = int(np.floor(p_test * num))\n",
    "    \n",
    "    index_tr_n = indices[: index_split]\n",
    "    index_te_n = indices[index_split:]\n",
    "    \n",
    "    rat_arr = ratings.toarray()\n",
    "    \n",
    "    # reshaping\n",
    "    valid_array_te = np.copy(rat_arr).reshape((num,1))\n",
    "    valid_array_tr = np.copy(rat_arr).reshape((num,1))  \n",
    "    \n",
    "    # create split\n",
    "    train = valid_array_tr\n",
    "    train[index_tr_n] = 0\n",
    "    train = train.reshape((row,col))\n",
    "    \n",
    "    test = valid_array_te\n",
    "    test[index_te_n] = 0\n",
    "    test = test.reshape((row,col))\n",
    "    \n",
    "    # ***************************************************\n",
    "    \n",
    "    #print (valid_ratings, train, test)\n",
    "    return rat_arr, train, test\n",
    "print(\"function 'compiled'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "rats, train, test = split_data(ratings, p_test=0.1, seed=46)\n",
    "print(\"done\")#2:10 much quicker than that :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions 'compiled'\n"
     ]
    }
   ],
   "source": [
    "def user_mean(data):\n",
    "    nnz_u = np.copy(data)\n",
    "    nnz_u[np.where( data > 0 )] = 1\n",
    "    return train.sum(axis=0) / nnz_u.sum(axis=0)\n",
    "\n",
    "def item_mean(data):\n",
    "    \n",
    "    nnz_i = np.copy(data)\n",
    "    nnz_i[np.where( data >1 )] = 1\n",
    "    return train.sum(axis=1) / nnz_i.sum(axis=1)\n",
    "    \n",
    "print(\"functions 'compiled'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 'compiled'\n"
     ]
    }
   ],
   "source": [
    "def init_MF_ALS_biased(train, num_features, factor_features=0.1, factor_biases=1):\n",
    "    num_items, num_users = train.shape\n",
    "    user_features = factor_features*np.ones((num_users,num_features))\n",
    "    item_features = factor_features*np.ones((num_items,num_features))\n",
    "    user_biases = factor_biases*np.ones(num_users)\n",
    "    item_biases = factor_biases*np.ones(num_items)\n",
    "    return user_features, item_features, user_biases, item_biases\n",
    "print(\"function 'compiled'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 'compiled'\n"
     ]
    }
   ],
   "source": [
    "def init_MF_ALS(train, num_features, factor_features=0.1):\n",
    "    num_items, num_users = train.shape\n",
    "    user_features = factor_features*np.ones((num_users,num_features))\n",
    "    item_features = factor_features*np.ones((num_items,num_features))\n",
    "    return user_features, item_features\n",
    "print(\"function 'compiled'\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions 'compiled'\n"
     ]
    }
   ],
   "source": [
    "def data_user_biased(data, user_biases):\n",
    "    data_user_biased = data - user_biases\n",
    "    return data_user_biased\n",
    "def data_item_biased(data, item_biases):\n",
    "    data_item_biased = (data.T - item_biases).T\n",
    "    return  data_item_biased\n",
    "print(\"functions 'compiled'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 'compiled'\n"
     ]
    }
   ],
   "source": [
    "def compute_error_prediction(data, prediction, nz):\n",
    "    real_label = np.array([data[d,n] for (d,n) in nz])\n",
    "    prediction_label = np.array([prediction[d,n] for (d,n) in nz])\n",
    "    rmse = np.sqrt((1/len(nz))*calculate_mse(real_label,prediction_label))\n",
    "    return rmse\n",
    "print(\"function 'compiled'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 'compiled'\n"
     ]
    }
   ],
   "source": [
    "def prediction_biased(item_features, item_biases, user_features, user_biases):    \n",
    "    prediction_data =    user_features.dot(item_features.T).T\n",
    "    prediction = ((prediction_data + user_biases).T + item_biases).T       \n",
    "    return prediction\n",
    "print(\"function 'compiled'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions 'compiled'\n"
     ]
    }
   ],
   "source": [
    "def update_item_biased_feature(train, user_features, user_biases, lambda_item, nnz_users_per_item, nz_item_userindices):\n",
    "    \n",
    "    num_users, num_features = user_features.shape\n",
    "    num_items = train.shape[0]\n",
    "    ones_biases = np.array([np.ones(num_users)])\n",
    "    item_biases = np.zeros(num_items)\n",
    "    item_features = np.zeros((num_items,num_features))         \n",
    "        \n",
    "    for item in np.arange(num_items): \n",
    "        nnz_users = nnz_users_per_item[item]\n",
    "        nz_userindices = nz_item_userindices[item]\n",
    "        nz_userfeatures = user_features[nz_userindices,:]\n",
    "        nz_onesbiases = ones_biases[:,nz_userindices]\n",
    "        nz_userbiases = user_biases[nz_userindices]\n",
    "    \n",
    "    \n",
    "        Xt = np.concatenate((nz_onesbiases, nz_userfeatures.T), axis=0)\n",
    "        A = Xt.dot(Xt.T) + lambda_item*nnz_users*np.eye(num_features+1)  \n",
    "        train_item = (train[item,nz_userindices])\n",
    "        b = Xt.dot(data_user_biased(train_item, nz_userbiases).T) \n",
    "\n",
    "        Yt = np.linalg.solve(A,b)\n",
    "        \n",
    "        item_features[item,:] = Yt[1:num_features+1]\n",
    "        item_biases[item] = Yt[0]\n",
    "\n",
    "    return item_features, item_biases\n",
    "\n",
    "def update_user_biased_feature(train, item_features, item_biases, lambda_user, nnz_items_per_user, nz_user_itemindices):\n",
    "    \n",
    "    num_users = train.shape[1]\n",
    "    num_items, num_features = item_features.shape\n",
    "    ones_biases = np.array([np.ones(num_items)])\n",
    "    user_biases = np.zeros(num_users)\n",
    "    user_features = np.zeros((num_users,num_features))\n",
    "    \n",
    "    for user in np.arange(num_users):        \n",
    "        nnz_items = nnz_items_per_user[user]\n",
    "        nz_itemindices = nz_user_itemindices[user]\n",
    "        nz_itemfeatures = item_features[nz_itemindices,:]\n",
    "        nz_onesbiases = ones_biases[:,nz_itemindices]\n",
    "        nz_itembiases = item_biases[nz_itemindices]\n",
    "        \n",
    "    \n",
    "        Yt = np.concatenate((nz_onesbiases, nz_itemfeatures.T), axis=0)\n",
    "        A = Yt.dot(Yt.T) + lambda_user*nnz_items*np.eye(num_features+1)  \n",
    "        train_user = train[nz_itemindices,user]\n",
    "        b = Yt.dot(data_item_biased(train_user, nz_itembiases)) \n",
    "        Xt = np.linalg.solve(A,b)\n",
    "        \n",
    "        user_features[user,:] = Xt[1:num_features+1]\n",
    "        user_biases[user] = Xt[0]\n",
    "\n",
    "    return user_features, user_biases\n",
    "\n",
    "print(\"functions 'compiled'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using ALS...\n",
      "iter: 0, RMSE on training set: 0.9942376202932252.\n",
      "iter: 1, RMSE on training set: 0.977796018913231.\n",
      "iter: 2, RMSE on training set: 0.9747794410155082.\n",
      "iter: 3, RMSE on training set: 0.9735733192748869.\n",
      "iter: 4, RMSE on training set: 0.9731092932921972.\n",
      "iter: 5, RMSE on training set: 0.9728947213461506.\n",
      "iter: 6, RMSE on training set: 0.959069630514617.\n",
      "iter: 7, RMSE on training set: 0.9000181762710602.\n",
      "Best iter: 6, with RMSE on test data: 0.9911782750011228. \n",
      "RMSE on test data: 1.0121953881685413.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def ALS_biased(train, test, seed=52):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 10   # K in the lecture notes\n",
    "    lambda_user = 0.01\n",
    "    lambda_item = 0.01\n",
    "    \n",
    "    stop_criterion = 1e-7\n",
    "    #change = 1\n",
    "    error_list = [0, 0]\n",
    "    max_it = 10 \n",
    "    \n",
    "    error_old = 10\n",
    "    error_new = 5\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features, user_biases, item_biases = init_MF_ALS_biased(train, num_features)\n",
    "    \n",
    "    # ***************************************************\n",
    "    \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))    \n",
    "    \n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "    \n",
    "    nz_train, nz_row_colindices, nz_col_rowindices = build_index_groups(train)\n",
    "    _,nz_user_itemindices = map(list,zip(*nz_col_rowindices))\n",
    "    nnz_items_per_user = [len(i) for i in nz_user_itemindices]\n",
    "    _,nz_item_userindices = map(list,zip(*nz_row_colindices))\n",
    "    nnz_users_per_item = [len(i) for i in nz_item_userindices]\n",
    "\n",
    "    print(\"learn the matrix factorization using ALS...\")\n",
    "\n",
    "    for it in np.arange(max_it):\n",
    "        \n",
    "        \n",
    "        item_features, item_biases = update_item_biased_feature(train, user_features, user_biases, lambda_item, nnz_users_per_item, nz_item_userindices)\n",
    "        user_features, user_biases = update_user_biased_feature(train, item_features, item_biases, lambda_user, nnz_items_per_user, nz_user_itemindices)\n",
    "        \n",
    "        prediction = prediction_biased(item_features, item_biases, user_features, user_biases)        \n",
    "        rmse = compute_error_prediction(train, prediction, nz_train)        \n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        \n",
    "        error_new = compute_error_prediction(test, prediction, nz_test)\n",
    "        \n",
    "        error_list.append(rmse)\n",
    "        if abs(error_list[-1]-error_list[-2])<stop_criterion:\n",
    "            break\n",
    "        if error_new>error_old:\n",
    "            print(\"Best iter: {}, with RMSE on test data: {}. \".format(it-1,error_old))\n",
    "            break\n",
    "        error_old = error_new\n",
    "\n",
    "    prediction = prediction_biased(item_features, item_biases, user_features, user_biases)\n",
    "    rmse = compute_error_prediction(test, prediction, nz_test)\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    print(\"done\")\n",
    "    \n",
    "    # ***************************************************\n",
    "\n",
    "ALS_biased(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 'compiled'\n"
     ]
    }
   ],
   "source": [
    "def prediction_non_biased(item_features, user_features):    \n",
    "    prediction = user_features.dot(item_features.T).T    \n",
    "    return prediction\n",
    "print(\"function 'compiled'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions 'compiled'\n"
     ]
    }
   ],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    # ***************************************************\n",
    "    num_items,num_users = train.shape\n",
    "    num_features = item_features.shape[1]\n",
    "    user_feature = np.zeros((num_users,num_features))\n",
    "    for user in np.arange(num_users):\n",
    "        nnz_items = nnz_items_per_user[user]\n",
    "        nz_itemindices = nz_user_itemindices[user]\n",
    "        nz_itemfeatures = item_features[nz_itemindices,:]\n",
    "        A = ((nz_itemfeatures.T).dot(nz_itemfeatures)+lambda_user*nnz_items*np.eye(num_features))\n",
    "        train_user = train[nz_itemindices,user]\n",
    "        b = ((nz_itemfeatures.T).dot(train_user))\n",
    "        user_feature[user,:] = np.linalg.solve(A,b)\n",
    "    # ***************************************************\n",
    "    return user_feature\n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    # ***************************************************\n",
    "    num_items,num_users = train.shape\n",
    "    num_features = user_features.shape[1]\n",
    "    item_feature = np.zeros((num_items,num_features))\n",
    "    for item in np.arange(num_items):\n",
    "        nnz_users = nnz_users_per_item[item]\n",
    "        nz_userindices = nz_item_userindices[item]\n",
    "        nz_userfeatures = user_features[nz_userindices,:]\n",
    "        A = ((nz_userfeatures.T).dot(nz_userfeatures)+lambda_item*nnz_users*np.eye(num_features))\n",
    "        train_item = (train[item,nz_userindices])\n",
    "        b = ((nz_userfeatures.T).dot(train_item))\n",
    "        item_feature[item,:] = np.linalg.solve(A,b)\n",
    "    # ***************************************************\n",
    "    return item_feature\n",
    "print(\"functions 'compiled'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using ALS...\n",
      "iter: 0, RMSE on training set: 0.9959192861108764.\n",
      "iter: 1, RMSE on training set: 0.9912939750943721.\n",
      "iter: 2, RMSE on training set: 0.9908659304261874.\n",
      "iter: 3, RMSE on training set: 0.990810472982908.\n",
      "iter: 4, RMSE on training set: 0.9908690709872654.\n",
      "RMSE on test data: 1.0025515814822392.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from helpers import build_index_groups\n",
    "np.seterr(all='raise') \n",
    "def ALS(train, test, seed=552):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 10   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.1\n",
    "    \n",
    "    stop_criterion = 1e-7\n",
    "    #change = 1\n",
    "    error_list = [0, 0]\n",
    "    max_it = 10 \n",
    "    \n",
    "    error_old = 10\n",
    "    error_new = 5\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF_ALS(train, num_features)\n",
    "    \n",
    "    # ***************************************************\n",
    "    \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))    \n",
    "    \n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "    \n",
    "    \n",
    "    nz_train, nz_row_colindices, nz_col_rowindices = build_index_groups(train)\n",
    "    _,nz_user_itemindices = map(list,zip(*nz_col_rowindices))\n",
    "    nnz_items_per_user = [len(i) for i in nz_user_itemindices]\n",
    "    _,nz_item_userindices = map(list,zip(*nz_row_colindices))\n",
    "    nnz_users_per_item = [len(i) for i in nz_item_userindices]\n",
    "\n",
    "    print(\"learn the matrix factorization using ALS...\")\n",
    "\n",
    "    for it in np.arange(max_it):\n",
    "        \n",
    "        item_features = update_item_feature(train, user_features, lambda_item, nnz_users_per_item, nz_item_userindices)\n",
    "\n",
    "        user_features = update_user_feature(train, item_features, lambda_user, nnz_items_per_user, nz_user_itemindices)\n",
    "        \n",
    "        prediction = prediction_non_biased(item_features, user_features)\n",
    "        \n",
    "        rmse = compute_error_prediction(train, prediction, nz_train)\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        \n",
    "        error_new = compute_error_prediction(test, prediction, nz_test)\n",
    "        error_list.append(rmse)\n",
    "        if abs(error_list[-1]-error_list[-2])<stop_criterion:\n",
    "            break\n",
    "        if error_new>error_old:\n",
    "            break\n",
    "        error_old = error_new\n",
    "        \n",
    "    prediction = prediction_non_biased(item_features, user_features)\n",
    "    rmse = compute_error_prediction(test, prediction, nz_test)\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    print(\"done\")\n",
    "    \n",
    "    # ***************************************************\n",
    "\n",
    "ALS(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#OLD CODE USELESS (KIND OF BAK FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "train_user_biased, train_item_biased = data_user_biased(train, user_biases),data_item_biased(train, item_biases)\n",
    "print(train_user_biased.shape)\n",
    "print(train_item_biased.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "u_mean = user_mean(train)\n",
    "i_mean = item_mean(train)\n",
    "\n",
    "print(u_mean.shape)\n",
    "print(i_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_features, item_features, user_biases, item_biases = init_MF_ALS_biased(train, 15)\n",
    "\n",
    "print(user_features.shape)\n",
    "print(item_features.shape)\n",
    "print(user_biases.shape)\n",
    "print(item_biases.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-250-f0ad8b18e8ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RMSE on test data: {}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mmatrix_factorization_SGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-250-f0ad8b18e8ed>\u001b[0m in \u001b[0;36mmatrix_factorization_SGD\u001b[1;34m(train, test)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnz_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# ***************************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction_non_biased\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_items\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnum_users\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mprediction_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-236-9ce04f7b878f>\u001b[0m in \u001b[0;36mprediction_non_biased\u001b[1;34m(item_features, user_features)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprediction_non_biased\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"function 'compiled'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def matrix_factorization_SGD(train, test): #rly bad\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    # define parameters\n",
    "    gamma = 0.01\n",
    "    num_features = 10   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    num_epochs = 20     # number of full passes through the train set\n",
    "    errors = [0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "\n",
    "    num_items, num_users = train.shape\n",
    "    \n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        #gamma /= 1.2\n",
    "        \n",
    "        \n",
    "        \n",
    "        for d, n in nz_train:\n",
    "        # ***************************************************\n",
    "            prediction = prediction_non_biased(item_features, user_features)\n",
    "            gradient = np.zeros(((num_items + num_users),num_features))\n",
    "            prediction_error = (train[d,n] - prediction[d,n])\n",
    "            #print(prediction_error)\n",
    "            #gradient entries for W\n",
    "            gradient[d,:] = -(prediction_error)*(user_features[n,:].T) + lambda_item*item_features[d,:]\n",
    "            #gradient entries for Z\n",
    "            gradient[num_items+n,:] = -(prediction_error)*(item_features[d,:]) + lambda_user*user_features[n,:]\n",
    "            \n",
    "            #update\n",
    "            item_features = item_features - gamma*(gradient[:num_items,:])\n",
    "            user_features = user_features - gamma*(gradient[num_items:,:])\n",
    "            \n",
    "        rmse = compute_error_biased(train, prediction, nz_train)\n",
    "\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        \n",
    "        errors.append(rmse)\n",
    "\n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "    # ***************************************************\n",
    "    # TODO\n",
    "    # evaluate the test error.\n",
    "    # ***************************************************\n",
    "    rmse = 0#compute_error_biased(test, user_features, item_features, nz_test)\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "\n",
    "matrix_factorization_SGD(train, test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_features, item_biases = update_item_biased_feature(train, user_features, user_biases, 0.01)\n",
    "\n",
    "print(item_features.shape)\n",
    "print(item_biases.shape)\n",
    "\n",
    "user_features, user_biases = update_user_biased_feature(train, item_features, item_biases, 0.01)\n",
    "\n",
    "print(user_features.shape)\n",
    "print(user_biases.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "    nz_train, nz_row_colindices, nz_col_rowindices = build_index_groups(train)\n",
    "    _,nz_user_itemindices = map(list,zip(*nz_col_rowindices))\n",
    "    nnz_items_per_user = [len(i) for i in nz_user_itemindices]\n",
    "    _,nz_item_userindices = map(list,zip(*nz_row_colindices))\n",
    "    nnz_users_per_item = [len(i) for i in nz_item_userindices]\n",
    "    max_it = 20\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8)\n",
      "(10000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(i_feat.dot(u_feat.T).shape)\n",
    "\n",
    "def update_item_feature(train, user_features, lambda_item):\n",
    "    num_users, num_features = user_features.shape\n",
    "    \n",
    "    Xt = user_features.T\n",
    "    A = Xt.dot(Xt.T) + lambda_item*np.eye(num_features)  \n",
    "    b = Xt.dot(train.T) \n",
    "\n",
    "    Yt = np.linalg.solve(A,b)\n",
    "    item_features = Yt.T\n",
    "\n",
    "    return item_features\n",
    "\n",
    "print(\"function 'compiled'\")\n",
    "\n",
    "def update_user_feature(train, item_features, lambda_user):\n",
    "    num_items, num_features = item_features.shape\n",
    "    \n",
    "    Yt = item_features.T\n",
    "    A = Yt.dot(Yt.T) + lambda_user*np.eye(num_features)  \n",
    "    b = Yt.dot(train) \n",
    "\n",
    "    Xt = np.linalg.solve(A,b)\n",
    "    user_features = Xt.T\n",
    "\n",
    "    return user_features\n",
    "\n",
    "print(\"function 'compiled'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Matrix factorisation using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run run.py 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run run.py 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Methods\n",
    "### CCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n",
      "number of items: 10000, number of users: 1000\n",
      "Preprocessing data\n",
      "Splitting data into train and test sets\n",
      "Training model\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0, RMSE on training set: 0.9960226377334059.\n",
      "iter: 1, RMSE on training set: 0.9960226376398212.\n",
      "RMSE on test data: 1.0065024878485005.\n",
      "RMSE on train data: 0.9960226376398212.\n",
      "RMSE on test data: 1.0065024878485005.\n"
     ]
    }
   ],
   "source": [
    "%run run.py 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_ratings, train_arr, test_arr = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)\n",
    "#plot_train_test_data(train_validation, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running num_features=1\n",
      "Running 1th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964587238475606.\n",
      "Running 2th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964584304313565.\n",
      "Running 3th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964523313834746.\n",
      "Running 4th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964418033298583.\n",
      "Running 5th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964463963413265.\n",
      "Running num_features=3\n",
      "Running 1th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0, RMSE on training set: 0.9968016355945376.\n",
      "iter: 1, RMSE on training set: 0.9955862627139658.\n",
      "iter: 2, RMSE on training set: 0.9955849744421196.\n",
      "RMSE on test data: 0.9955935180106164.\n",
      "Running 2th fold in 5 folds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-286ac0b41682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running num_features={n}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     [train_rmse_arr, validation_rmse_arr] = cross_validation(ratings, K, method, num_items_per_user, \n\u001b[0;32m---> 22\u001b[0;31m                                                              num_users_per_item, min_num_ratings, num_features, lambda_user, lambda_item)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m## Calculate mean and standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asmaetounsi/Documents/Etudes/EPFL/pattern/PCML_project2/code/cross_validation.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(ratings, K, method, num_items_per_user, num_users_per_item, min_num_ratings, num_features, lambda_user, lambda_item, gamma)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running {}th fold in {} folds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m### Split data in kth fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_fold_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffled_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m### Matrix factorization using SGD/ALS/CCD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asmaetounsi/Documents/Etudes/EPFL/pattern/PCML_project2/code/cross_validation.py\u001b[0m in \u001b[0;36mk_fold_generator\u001b[0;34m(X, K, kth_fold, batch_size, data_size, shuffled_index)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXdense\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffled_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetxor1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_val_ind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_val_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXdense\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m                  \u001b[0;31m## Training data indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlil_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlil_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m## Return sparse matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asmaetounsi/anaconda3/lib/python3.5/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asmaetounsi/anaconda3/lib/python3.5/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__array_finalize__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## !!! Takes long time to run\n",
    "\n",
    "method = 2     # 0-SGD 1-ALS\n",
    "K = 5         ## K-fold cross validation\n",
    "gamma = 0.01\n",
    "num_features_arr = [1, 3, 5, 7, 10, 13, 15]   # K in the lecture notes\n",
    "lambda_user = 0.1\n",
    "lambda_item = 0.7\n",
    "min_num_ratings=10\n",
    "\n",
    "train_rmse_mean = np.zeros(len(num_features_arr))\n",
    "train_rmse_std = np.zeros(len(num_features_arr))\n",
    "validation_rmse_mean = np.zeros(len(num_features_arr))\n",
    "validation_rmse_std = np.zeros(len(num_features_arr))\n",
    "\n",
    "for i, num_features in enumerate(num_features_arr):\n",
    "    train_rmse_arr = []\n",
    "    validation_rmse_arr = []\n",
    "    \n",
    "    print('Running num_features={n}'.format(n=num_features))\n",
    "    [train_rmse_arr, validation_rmse_arr] = cross_validation(ratings, K, method, num_items_per_user, \n",
    "                                                             num_users_per_item, min_num_ratings, num_features, lambda_user, lambda_item)\n",
    "        \n",
    "    ## Calculate mean and standard deviation    \n",
    "    train_rmse_mean[i] = np.mean(train_rmse_arr)\n",
    "    train_rmse_std[i] = np.std(train_rmse_arr)\n",
    "    validation_rmse_mean[i] = np.mean(validation_rmse_arr)\n",
    "    validation_rmse_std[i] = np.std(validation_rmse_std)\n",
    "    \n",
    "## Plotting results\n",
    "plt.fill_between(num_features_arr, train_rmse_mean - train_rmse_std,\n",
    "                     train_rmse_mean + train_rmse_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(num_features_arr, validation_rmse_mean - validation_rmse_std,\n",
    "                     validation_rmse_mean + validation_rmse_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(num_features_arr, train_rmse_mean, 'o-', color=\"r\")\n",
    "plt.plot(num_features_arr, validation_rmse_mean, 'o-', color=\"g\")\n",
    "plt.legend(('Train', 'Validation'))\n",
    "plt.xlabel('Number of features (K)'); plt.ylabel('RMSE');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99236697]\n",
      "[  1.11022302e-16]\n",
      "[ 0.99235064]\n",
      "[ 0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_rmse_mean)\n",
    "print(train_rmse_std)\n",
    "print(validation_rmse_mean)\n",
    "print(validation_rmse_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lambda_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running lambda_user=0.01\n",
      "Running 1th fold in 10 folds\n"
     ]
    }
   ],
   "source": [
    "## !!! Takes long time to run\n",
    "\n",
    "method = 2     # 0-SGD 1-ALS\n",
    "K = 10        ## K-fold cross validation\n",
    "gamma = 0.01\n",
    "num_features = 20   # K in the lecture notes\n",
    "lambda_user_arr = [0.01, 0.1, 1, 10]\n",
    "lambda_item = 0.7\n",
    "\n",
    "train_rmse_mean = np.zeros(len(lambda_user_arr))\n",
    "train_rmse_std = np.zeros(len(lambda_user_arr))\n",
    "validation_rmse_mean = np.zeros(len(lambda_user_arr))\n",
    "validation_rmse_std = np.zeros(len(lambda_user_arr))\n",
    "\n",
    "for i, lambda_user in enumerate(lambda_user_arr):\n",
    "    train_rmse_arr = []\n",
    "    validation_rmse_arr = []\n",
    "    \n",
    "    print('Running lambda_user={n}'.format(n=lambda_user))\n",
    "    [train_rmse_arr, validation_rmse_arr] = cross_validation(ratings, K, method, num_items_per_user, \n",
    "                                                             num_users_per_item, min_num_ratings=10)\n",
    "        \n",
    "    train_rmse_mean[i] = np.mean(train_rmse_arr)\n",
    "    train_rmse_std[i] = np.std(train_rmse_arr)\n",
    "    validation_rmse_mean[i] = np.mean(validation_rmse_arr)\n",
    "    validation_rmse_std[i] = np.std(validation_rmse_std)\n",
    "    \n",
    "## Plotting results\n",
    "plt.fill_between(lambda_user_arr, train_rmse_mean - train_rmse_std,\n",
    "                     train_rmse_mean + train_rmse_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(lambda_user_arr, validation_rmse_mean - validation_rmse_std,\n",
    "                     validation_rmse_mean + validation_rmse_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(lambda_user_arr, train_rmse_mean, 'o-', color=\"r\")\n",
    "plt.plot(lambda_user_arr, validation_rmse_mean, 'o-', color=\"g\")\n",
    "plt.legend(('Train', 'Validation'))\n",
    "plt.xlabel('Lambda user'); plt.ylabel('RMSE');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## !!! Takes long time to run\n",
    "\n",
    "method = 0     # 0-SGD 1-ALS\n",
    "K = 10        ## K-fold cross validation\n",
    "gamma = 0.01\n",
    "num_features = 20   # K in the lecture notes\n",
    "lambda_user = 0.1\n",
    "lambda_item_arr = [0.01, 0.1, 0.5, 1]\n",
    "\n",
    "train_rmse_mean = np.zeros(len(lambda_item_arr))\n",
    "train_rmse_std = np.zeros(len(lambda_item_arr))\n",
    "validation_rmse_mean = np.zeros(len(lambda_item_arr))\n",
    "validation_rmse_std = np.zeros(len(lambda_item_arr))\n",
    "\n",
    "for i, lambda_item in enumerate(lambda_item_arr):\n",
    "    train_rmse_arr = []\n",
    "    validation_rmse_arr = []\n",
    "    \n",
    "    print('Running lambda_item={n}'.format(n=lambda_item))\n",
    "    [train_rmse_arr, validation_rmse_arr] = cross_validation(ratings, K, method, num_items_per_user, \n",
    "                                                             num_users_per_item, min_num_ratings=10)\n",
    "        \n",
    "    train_rmse_mean[i] = np.mean(train_rmse_arr)\n",
    "    train_rmse_std[i] = np.std(train_rmse_arr)\n",
    "    validation_rmse_mean[i] = np.mean(validation_rmse_arr)\n",
    "    validation_rmse_std[i] = np.std(validation_rmse_std)\n",
    "    \n",
    "## Plotting results\n",
    "plt.fill_between(lambda_item_arr, train_rmse_mean - train_rmse_std,\n",
    "                     train_rmse_mean + train_rmse_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(lambda_item_arr, validation_rmse_mean - validation_rmse_std,\n",
    "                     validation_rmse_mean + validation_rmse_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(lambda_item_arr, train_rmse_mean, 'o-', color=\"r\")\n",
    "plt.plot(lambda_item_arr, validation_rmse_mean, 'o-', color=\"g\")\n",
    "plt.legend(('Train', 'Validation'))\n",
    "plt.xlabel('Lambda item'); plt.ylabel('RMSE');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## !!! Takes long time to run\n",
    "\n",
    "method = 0     # 0-SGD\n",
    "K = 10        ## K-fold cross validation\n",
    "gamma_arr = [0.01, 0.1, 1]\n",
    "num_features = 20   # K in the lecture notes\n",
    "lambda_user = 0.1\n",
    "lambda_item = 0.5\n",
    "\n",
    "train_rmse_mean = np.zeros(len(gamma_arr))\n",
    "train_rmse_std = np.zeros(len(gamma_arr))\n",
    "validation_rmse_mean = np.zeros(len(gamma_arr))\n",
    "validation_rmse_std = np.zeros(len(gamma_arr))\n",
    "\n",
    "for i, gamma in enumerate(gamma_arr):\n",
    "    train_rmse_arr = []\n",
    "    validation_rmse_arr = []\n",
    "    \n",
    "    print('Running gamma={n}'.format(n=gamma))\n",
    "    [train_rmse_arr, validation_rmse_arr] = cross_validation(ratings, K, method, num_items_per_user, \n",
    "                                                             num_users_per_item, min_num_ratings=10)\n",
    "        \n",
    "    train_rmse_mean[i] = np.mean(train_rmse_arr)\n",
    "    train_rmse_std[i] = np.std(train_rmse_arr)\n",
    "    validation_rmse_mean[i] = np.mean(validation_rmse_arr)\n",
    "    validation_rmse_std[i] = np.std(validation_rmse_std)\n",
    "    \n",
    "## Plotting results\n",
    "plt.fill_between(gamma_arr, train_rmse_mean - train_rmse_std,\n",
    "                     train_rmse_mean + train_rmse_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(gamma_arr, validation_rmse_mean - validation_rmse_std,\n",
    "                     validation_rmse_mean + validation_rmse_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(gamma_arr, train_rmse_mean, 'o-', color=\"r\")\n",
    "plt.plot(gamma_arr, validation_rmse_mean, 'o-', color=\"g\")\n",
    "plt.legend(('Train', 'Validation'))\n",
    "plt.xlabel('Learning Rate'); plt.ylabel('RMSE');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "#### 1. Compare SGD, ALS with the best set of parameters (based on above results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
