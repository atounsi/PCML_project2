{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from helpers import *\n",
    "from plots import *\n",
    "from plots import *\n",
    "from split_data import *\n",
    "from recommender import *\n",
    "from cross_validation import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\u001c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "path_dataset = \"../data/data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEbCAYAAABgLnslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncs45l1n/HyRRptq0/AuwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103f6f7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 8, min # of users per item = 3.\n"
     ]
    }
   ],
   "source": [
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_ratings, train_validation, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)\n",
    "#plot_train_test_data(train_validation, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Matrix factorisation using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run run.py 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run run.py 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Methods\n",
    "### CCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n",
      "number of items: 10000, number of users: 1000\n",
      "Preprocessing data\n",
      "Splitting data into train and test sets\n",
      "Training model\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 2.9950929124619052.\n",
      "iter: 1.0, RMSE on training set: 2.8375133312177385.\n",
      "iter: 2.0, RMSE on training set: 2.698924358850894.\n",
      "iter: 3.0, RMSE on training set: 2.5769580418708635.\n",
      "iter: 4.0, RMSE on training set: 2.4695058435338724.\n",
      "iter: 5.0, RMSE on training set: 2.3747001823458365.\n",
      "iter: 6.0, RMSE on training set: 2.2908928062854743.\n",
      "iter: 7.0, RMSE on training set: 2.2166350497167655.\n",
      "iter: 8.0, RMSE on training set: 2.1506589227177604.\n",
      "iter: 9.0, RMSE on training set: 2.0918589698662795.\n",
      "iter: 10.0, RMSE on training set: 2.0392749650854327.\n",
      "iter: 11.0, RMSE on training set: 1.9920755622374824.\n",
      "iter: 12.0, RMSE on training set: 1.949543027272273.\n",
      "iter: 13.0, RMSE on training set: 1.9110591555029883.\n",
      "iter: 14.0, RMSE on training set: 1.8760924395755691.\n",
      "iter: 15.0, RMSE on training set: 1.8441865107720288.\n",
      "iter: 16.0, RMSE on training set: 1.8149498360746452.\n",
      "iter: 17.0, RMSE on training set: 1.7880466202723584.\n",
      "iter: 18.0, RMSE on training set: 1.763188838006205.\n",
      "iter: 19.0, RMSE on training set: 1.740129304928859.\n",
      "iter: 20.0, RMSE on training set: 1.7186556889934048.\n",
      "iter: 21.0, RMSE on training set: 1.6985853607671593.\n",
      "iter: 22.0, RMSE on training set: 1.6797609840183791.\n",
      "iter: 23.0, RMSE on training set: 1.6620467532315155.\n",
      "iter: 24.0, RMSE on training set: 1.6453251919953749.\n",
      "iter: 25.0, RMSE on training set: 1.6294944344610105.\n",
      "iter: 26.0, RMSE on training set: 1.6144659206067447.\n",
      "iter: 27.0, RMSE on training set: 1.6001624444076923.\n",
      "iter: 28.0, RMSE on training set: 1.5865165018872058.\n",
      "iter: 29.0, RMSE on training set: 1.5734688932574752.\n",
      "iter: 30.0, RMSE on training set: 1.5609675398599663.\n",
      "iter: 31.0, RMSE on training set: 1.5489664823792688.\n",
      "iter: 32.0, RMSE on training set: 1.5374250318510028.\n",
      "iter: 33.0, RMSE on training set: 1.5263070493615978.\n",
      "iter: 34.0, RMSE on training set: 1.515580334102754.\n",
      "iter: 35.0, RMSE on training set: 1.5052161026589794.\n",
      "iter: 36.0, RMSE on training set: 1.4951885451373188.\n",
      "iter: 37.0, RMSE on training set: 1.4854744460575666.\n",
      "iter: 38.0, RMSE on training set: 1.4760528598679963.\n",
      "iter: 39.0, RMSE on training set: 1.4669048325894816.\n",
      "iter: 40.0, RMSE on training set: 1.4580131624664743.\n",
      "iter: 41.0, RMSE on training set: 1.4493621936568162.\n",
      "iter: 42.0, RMSE on training set: 1.440937637958127.\n",
      "iter: 43.0, RMSE on training set: 1.4327264203760235.\n",
      "iter: 44.0, RMSE on training set: 1.4247165450141406.\n",
      "iter: 45.0, RMSE on training set: 1.4168969783293368.\n",
      "iter: 46.0, RMSE on training set: 1.4092575472660198.\n",
      "iter: 47.0, RMSE on training set: 1.4017888501762632.\n",
      "iter: 48.0, RMSE on training set: 1.3944821787603745.\n",
      "iter: 49.0, RMSE on training set: 1.3873294495360375.\n",
      "iter: 50.0, RMSE on training set: 1.3803231435725267.\n",
      "iter: 51.0, RMSE on training set: 1.3734562534168318.\n",
      "iter: 52.0, RMSE on training set: 1.3667222362974638.\n",
      "iter: 53.0, RMSE on training set: 1.3601149728243156.\n",
      "iter: 54.0, RMSE on training set: 1.3536287305136576.\n",
      "iter: 55.0, RMSE on training set: 1.3472581315596857.\n",
      "iter: 56.0, RMSE on training set: 1.3409981243513214.\n",
      "iter: 57.0, RMSE on training set: 1.334843958297346.\n",
      "iter: 58.0, RMSE on training set: 1.3287911615771115.\n",
      "iter: 59.0, RMSE on training set: 1.3228355214794054.\n",
      "iter: 60.0, RMSE on training set: 1.3169730670305941.\n",
      "iter: 61.0, RMSE on training set: 1.3112000536458304.\n",
      "iter: 62.0, RMSE on training set: 1.3055129495654407.\n",
      "iter: 63.0, RMSE on training set: 1.2999084238630858.\n",
      "iter: 64.0, RMSE on training set: 1.29438333583392.\n",
      "iter: 65.0, RMSE on training set: 1.2889347255900612.\n",
      "iter: 66.0, RMSE on training set: 1.2835598057077426.\n",
      "iter: 67.0, RMSE on training set: 1.278255953785729.\n",
      "iter: 68.0, RMSE on training set: 1.2730207057882998.\n",
      "iter: 69.0, RMSE on training set: 1.267851750058399.\n",
      "iter: 70.0, RMSE on training set: 1.2627469218977694.\n",
      "iter: 71.0, RMSE on training set: 1.2577041986210435.\n",
      "iter: 72.0, RMSE on training set: 1.2527216950001052.\n",
      "iter: 73.0, RMSE on training set: 1.2477976590236646.\n",
      "iter: 74.0, RMSE on training set: 1.242930467904914.\n",
      "iter: 75.0, RMSE on training set: 1.238118624277597.\n",
      "iter: 76.0, RMSE on training set: 1.2333607525276744.\n",
      "iter: 77.0, RMSE on training set: 1.2286555952142264.\n",
      "iter: 78.0, RMSE on training set: 1.2240020095392434.\n",
      "iter: 79.0, RMSE on training set: 1.219398963831547.\n",
      "iter: 80.0, RMSE on training set: 1.214845534015374.\n",
      "iter: 81.0, RMSE on training set: 1.2103409000390697.\n",
      "iter: 82.0, RMSE on training set: 1.2058843422439653.\n",
      "iter: 83.0, RMSE on training set: 1.2014752376578703.\n",
      "iter: 84.0, RMSE on training set: 1.1971130562016397.\n",
      "iter: 85.0, RMSE on training set: 1.1927973568010817.\n",
      "iter: 86.0, RMSE on training set: 1.1885277833999905.\n",
      "iter: 87.0, RMSE on training set: 1.184304060873265.\n",
      "iter: 88.0, RMSE on training set: 1.1801259908420894.\n",
      "iter: 89.0, RMSE on training set: 1.1759934473957403.\n",
      "iter: 90.0, RMSE on training set: 1.1719063727270331.\n",
      "iter: 91.0, RMSE on training set: 1.167864772690451.\n",
      "iter: 92.0, RMSE on training set: 1.1638687122939024.\n",
      "iter: 93.0, RMSE on training set: 1.1599183111364988.\n",
      "iter: 94.0, RMSE on training set: 1.1560137388061325.\n",
      "iter: 95.0, RMSE on training set: 1.152155210251541.\n",
      "iter: 96.0, RMSE on training set: 1.1483429811443606.\n",
      "iter: 97.0, RMSE on training set: 1.144577343247124.\n",
      "iter: 98.0, RMSE on training set: 1.1408586198034265.\n",
      "iter: 99.0, RMSE on training set: 1.137187160966526.\n",
      "iter: 100.0, RMSE on training set: 1.133563339282457.\n",
      "iter: 101.0, RMSE on training set: 1.1299875452434098.\n",
      "iter: 102.0, RMSE on training set: 1.1264601829266339.\n",
      "iter: 103.0, RMSE on training set: 1.1229816657334972.\n",
      "iter: 104.0, RMSE on training set: 1.1195524122426386.\n",
      "iter: 105.0, RMSE on training set: 1.1161728421903083.\n",
      "iter: 106.0, RMSE on training set: 1.1128433725901763.\n",
      "iter: 107.0, RMSE on training set: 1.1095644140039398.\n",
      "iter: 108.0, RMSE on training set: 1.1063363669731185.\n",
      "iter: 109.0, RMSE on training set: 1.1031596186214798.\n",
      "iter: 110.0, RMSE on training set: 1.1000345394364839.\n",
      "iter: 111.0, RMSE on training set: 1.0969614802371752.\n",
      "iter: 112.0, RMSE on training set: 1.0939407693348857.\n",
      "iter: 113.0, RMSE on training set: 1.0909727098921183.\n",
      "iter: 114.0, RMSE on training set: 1.088057577483889.\n",
      "iter: 115.0, RMSE on training set: 1.0851956178648468.\n",
      "iter: 116.0, RMSE on training set: 1.0823870449443806.\n",
      "iter: 117.0, RMSE on training set: 1.079632038970979.\n",
      "iter: 118.0, RMSE on training set: 1.076930744926076.\n",
      "iter: 119.0, RMSE on training set: 1.0742832711266361.\n",
      "iter: 120.0, RMSE on training set: 1.0716896880348525.\n",
      "iter: 121.0, RMSE on training set: 1.0691500272723484.\n",
      "iter: 122.0, RMSE on training set: 1.0666642808354825.\n",
      "iter: 123.0, RMSE on training set: 1.064232400507507.\n",
      "iter: 124.0, RMSE on training set: 1.061854297462582.\n",
      "iter: 125.0, RMSE on training set: 1.0595298420559118.\n",
      "iter: 126.0, RMSE on training set: 1.0572588637936327.\n",
      "iter: 127.0, RMSE on training set: 1.0550411514754612.\n",
      "iter: 128.0, RMSE on training set: 1.0528764535025639.\n",
      "iter: 129.0, RMSE on training set: 1.0507644783426207.\n",
      "iter: 130.0, RMSE on training set: 1.0487048951436038.\n",
      "iter: 131.0, RMSE on training set: 1.046697334487469.\n",
      "iter: 132.0, RMSE on training set: 1.044741389274569.\n",
      "iter: 133.0, RMSE on training set: 1.0428366157294342.\n",
      "iter: 134.0, RMSE on training set: 1.0409825345183268.\n",
      "iter: 135.0, RMSE on training set: 1.0391786319688625.\n",
      "iter: 136.0, RMSE on training set: 1.037424361381951.\n",
      "iter: 137.0, RMSE on training set: 1.0357191444262908.\n",
      "iter: 138.0, RMSE on training set: 1.0340623726057043.\n",
      "iter: 139.0, RMSE on training set: 1.032453408789732.\n",
      "iter: 140.0, RMSE on training set: 1.0308915887980297.\n",
      "iter: 141.0, RMSE on training set: 1.0293762230293635.\n",
      "iter: 142.0, RMSE on training set: 1.0279065981261855.\n",
      "iter: 143.0, RMSE on training set: 1.0264819786661297.\n",
      "iter: 144.0, RMSE on training set: 1.0251016088720142.\n",
      "iter: 145.0, RMSE on training set: 1.0237647143323487.\n",
      "iter: 146.0, RMSE on training set: 1.0224705037246753.\n",
      "iter: 147.0, RMSE on training set: 1.0212181705344958.\n",
      "iter: 148.0, RMSE on training set: 1.020006894762938.\n",
      "iter: 149.0, RMSE on training set: 1.0188358446167638.\n",
      "iter: 150.0, RMSE on training set: 1.0177041781747411.\n",
      "iter: 151.0, RMSE on training set: 1.016611045024874.\n",
      "iter: 152.0, RMSE on training set: 1.0155555878674312.\n",
      "iter: 153.0, RMSE on training set: 1.014536944079172.\n",
      "iter: 154.0, RMSE on training set: 1.0135542472346215.\n",
      "iter: 155.0, RMSE on training set: 1.0126066285807058.\n",
      "iter: 156.0, RMSE on training set: 1.011693218461488.\n",
      "iter: 157.0, RMSE on training set: 1.0108131476901934.\n",
      "iter: 158.0, RMSE on training set: 1.0099655488661057.\n",
      "iter: 159.0, RMSE on training set: 1.0091495576343674.\n",
      "iter: 160.0, RMSE on training set: 1.0083643138870448.\n",
      "iter: 161.0, RMSE on training set: 1.007608962904249.\n",
      "iter: 162.0, RMSE on training set: 1.0068826564344022.\n",
      "iter: 163.0, RMSE on training set: 1.006184553713112.\n",
      "iter: 164.0, RMSE on training set: 1.0055138224204048.\n",
      "iter: 165.0, RMSE on training set: 1.0048696395763415.\n",
      "iter: 166.0, RMSE on training set: 1.0042511923753539.\n",
      "iter: 167.0, RMSE on training set: 1.0036576789598155.\n",
      "iter: 168.0, RMSE on training set: 1.0030883091336416.\n",
      "iter: 169.0, RMSE on training set: 1.0025423050168702.\n",
      "iter: 170.0, RMSE on training set: 1.0020189016423795.\n",
      "iter: 171.0, RMSE on training set: 1.0015173474960257.\n",
      "iter: 172.0, RMSE on training set: 1.0010369050016446.\n",
      "iter: 173.0, RMSE on training set: 1.00057685095247.\n",
      "iter: 174.0, RMSE on training set: 1.0001364768906074.\n",
      "iter: 175.0, RMSE on training set: 0.9997150894362942.\n",
      "iter: 176.0, RMSE on training set: 0.9993120105687514.\n",
      "iter: 177.0, RMSE on training set: 0.9989265778604557.\n",
      "iter: 178.0, RMSE on training set: 0.9985581446667368.\n",
      "iter: 179.0, RMSE on training set: 0.9982060802725955.\n",
      "iter: 180.0, RMSE on training set: 0.9978697699986987.\n",
      "iter: 181.0, RMSE on training set: 0.9975486152684686.\n",
      "iter: 182.0, RMSE on training set: 0.997242033638235.\n",
      "iter: 183.0, RMSE on training set: 0.9969494587923851.\n",
      "iter: 184.0, RMSE on training set: 0.9966703405054541.\n",
      "iter: 185.0, RMSE on training set: 0.9964041445730819.\n",
      "iter: 186.0, RMSE on training set: 0.9961503527137577.\n",
      "iter: 187.0, RMSE on training set: 0.995908462443239.\n",
      "iter: 188.0, RMSE on training set: 0.9956779869235384.\n",
      "iter: 189.0, RMSE on training set: 0.9954584547883318.\n",
      "iter: 190.0, RMSE on training set: 0.9952494099466169.\n",
      "iter: 191.0, RMSE on training set: 0.995050411366437.\n",
      "iter: 192.0, RMSE on training set: 0.9948610328404519.\n",
      "iter: 193.0, RMSE on training set: 0.9946808627350946.\n",
      "iter: 194.0, RMSE on training set: 0.994509503725018.\n",
      "iter: 195.0, RMSE on training set: 0.9943465725145186.\n",
      "iter: 196.0, RMSE on training set: 0.9941916995475322.\n",
      "iter: 197.0, RMSE on training set: 0.9940445287077938.\n",
      "iter: 198.0, RMSE on training set: 0.9939047170106623.\n",
      "iter: 199.0, RMSE on training set: 0.9937719342880723.\n",
      "iter: 200.0, RMSE on training set: 0.9936458628679986.\n",
      "iter: 201.0, RMSE on training set: 0.9935261972497534.\n",
      "iter: 202.0, RMSE on training set: 0.993412643776371.\n",
      "iter: 203.0, RMSE on training set: 0.9933049203052366.\n",
      "iter: 204.0, RMSE on training set: 0.9932027558780667.\n",
      "iter: 205.0, RMSE on training set: 0.993105890391254.\n",
      "RMSE on test data: 1.0128703895487268.\n",
      "RMSE on train data: 0.993105890391254.\n",
      "RMSE on test data: 1.0128703895487268.\n"
     ]
    }
   ],
   "source": [
    "%run run.py 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running num_features=1\n",
      "Running 1th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964587238475606.\n",
      "Running 2th fold in 5 folds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-286ac0b41682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running num_features={n}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     [train_rmse_arr, validation_rmse_arr] = cross_validation(ratings, K, method, num_items_per_user, \n\u001b[0;32m---> 22\u001b[0;31m                                                              num_users_per_item, min_num_ratings, num_features, lambda_user, lambda_item)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m## Calculate mean and standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asmaetounsi/Documents/Etudes/EPFL/pattern/PCML_project2/code/cross_validation.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(ratings, K, method, num_items_per_user, num_users_per_item, min_num_ratings, num_features, lambda_user, lambda_item, gamma)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running {}th fold in {} folds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m### Split data in kth fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_fold_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffled_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m### Matrix factorization using SGD/ALS/CCD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asmaetounsi/Documents/Etudes/EPFL/pattern/PCML_project2/code/cross_validation.py\u001b[0m in \u001b[0;36mk_fold_generator\u001b[0;34m(X, K, kth_fold, batch_size, data_size, shuffled_index)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffled_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetxor1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_val_ind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_val_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXdense\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m                  \u001b[0;31m## Training data indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlil_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlil_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m## Return sparse matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \"\"\"\n",
      "\u001b[0;32m/Users/asmaetounsi/anaconda3/lib/python3.5/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asmaetounsi/anaconda3/lib/python3.5/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36mtolil\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtolil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlil_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mlil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlil_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# lil_matrix needs sorted column indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asmaetounsi/anaconda3/lib/python3.5/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized lil_matrix constructor usage'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## !!! Takes long time to run\n",
    "\n",
    "method = 2     # 0-SGD 1-ALS\n",
    "K = 5         ## K-fold cross validation\n",
    "gamma = 0.01\n",
    "num_features_arr = [1, 3, 5, 7, 10, 13, 15]   # K in the lecture notes\n",
    "lambda_user = 0.1\n",
    "lambda_item = 0.7\n",
    "min_num_ratings=10\n",
    "\n",
    "train_rmse_mean = np.zeros(len(num_features_arr))\n",
    "train_rmse_std = np.zeros(len(num_features_arr))\n",
    "validation_rmse_mean = np.zeros(len(num_features_arr))\n",
    "validation_rmse_std = np.zeros(len(num_features_arr))\n",
    "\n",
    "for i, num_features in enumerate(num_features_arr):\n",
    "    train_rmse_arr = []\n",
    "    validation_rmse_arr = []\n",
    "    \n",
    "    print('Running num_features={n}'.format(n=num_features))\n",
    "    [train_rmse_arr, validation_rmse_arr] = cross_validation(ratings, K, method, num_items_per_user, \n",
    "                                                             num_users_per_item, min_num_ratings, num_features, lambda_user, lambda_item)\n",
    "        \n",
    "    ## Calculate mean and standard deviation    \n",
    "    train_rmse_mean[i] = np.mean(train_rmse_arr)\n",
    "    train_rmse_std[i] = np.std(train_rmse_arr)\n",
    "    validation_rmse_mean[i] = np.mean(validation_rmse_arr)\n",
    "    validation_rmse_std[i] = np.std(validation_rmse_std)\n",
    "    \n",
    "## Plotting results\n",
    "plt.fill_between(num_features_arr, train_rmse_mean - train_rmse_std,\n",
    "                     train_rmse_mean + train_rmse_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(num_features_arr, validation_rmse_mean - validation_rmse_std,\n",
    "                     validation_rmse_mean + validation_rmse_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(num_features_arr, train_rmse_mean, 'o-', color=\"r\")\n",
    "plt.plot(num_features_arr, validation_rmse_mean, 'o-', color=\"g\")\n",
    "plt.legend(('Train', 'Validation'))\n",
    "plt.xlabel('Number of features (K)'); plt.ylabel('RMSE');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99645032  0.99644168  0.          0.          0.          0.          0.        ]\n",
      "[  1.11022302e-16   1.11022302e-16   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      "[ 0.99645154  0.99644258  0.          0.          0.          0.          0.        ]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_rmse_mean)\n",
    "print(train_rmse_std)\n",
    "print(validation_rmse_mean)\n",
    "print(validation_rmse_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lambda_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running lambda_user=0.01\n",
      "Running 1th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964587238475606.\n",
      "Running 2th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964584304313565.\n",
      "Running 3th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964523313834746.\n",
      "Running 4th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964418033298583.\n",
      "Running 5th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964463963413265.\n",
      "Running lambda_user=0.1\n",
      "Running 1th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964587238475606.\n",
      "Running 2th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964584304313565.\n",
      "Running 3th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964523313834746.\n",
      "Running 4th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964418033298583.\n",
      "Running 5th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964463963413265.\n",
      "Running lambda_user=1\n",
      "Running 1th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964587238475606.\n",
      "Running 2th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964584304313565.\n",
      "Running 3th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964523313834746.\n",
      "Running 4th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964418033298583.\n",
      "Running 5th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964463963413265.\n",
      "Running lambda_user=10\n",
      "Running 1th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964587238475606.\n",
      "Running 2th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964584304313565.\n",
      "Running 3th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964523313834746.\n",
      "Running 4th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964418033298583.\n",
      "Running 5th fold in 5 folds\n",
      "learn the matrix factorization using CCD...\n",
      "iter: 0.0, RMSE on training set: 0.9964503244960371.\n",
      "iter: 1.0, RMSE on training set: 0.9964503242477375.\n",
      "RMSE on test data: 0.9964463963413265.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAEVCAYAAAC8DdERAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYJmZWVlwwDIzs7Lw/wHr0CpPTFJcHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b400e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## !!! Takes long time to run\n",
    "\n",
    "method = 2     # 0-SGD 1-ALS\n",
    "K = 5        ## K-fold cross validation\n",
    "gamma = 0.01\n",
    "num_features = 10   # K in the lecture notes\n",
    "lambda_user_arr = [0.01, 0.1, 1, 10]\n",
    "lambda_item = 0.7\n",
    "\n",
    "train_rmse_mean = np.zeros(len(lambda_user_arr))\n",
    "train_rmse_std = np.zeros(len(lambda_user_arr))\n",
    "validation_rmse_mean = np.zeros(len(lambda_user_arr))\n",
    "validation_rmse_std = np.zeros(len(lambda_user_arr))\n",
    "\n",
    "for i, lambda_user in enumerate(lambda_user_arr):\n",
    "    train_rmse_arr = []\n",
    "    validation_rmse_arr = []\n",
    "    \n",
    "    print('Running lambda_user={n}'.format(n=lambda_user))\n",
    "    [train_rmse_arr, validation_rmse_arr] = cross_validation(ratings, K, method, num_items_per_user, \n",
    "                                                             num_users_per_item, min_num_ratings,  num_features, lambda_user, lambda_item)\n",
    "        \n",
    "    train_rmse_mean[i] = np.mean(train_rmse_arr)\n",
    "    train_rmse_std[i] = np.std(train_rmse_arr)\n",
    "    validation_rmse_mean[i] = np.mean(validation_rmse_arr)\n",
    "    validation_rmse_std[i] = np.std(validation_rmse_std)\n",
    "    \n",
    "## Plotting results\n",
    "plt.fill_between(lambda_user_arr, train_rmse_mean - train_rmse_std,\n",
    "                     train_rmse_mean + train_rmse_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(lambda_user_arr, validation_rmse_mean - validation_rmse_std,\n",
    "                     validation_rmse_mean + validation_rmse_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(lambda_user_arr, train_rmse_mean, 'o-', color=\"r\")\n",
    "plt.plot(lambda_user_arr, validation_rmse_mean, 'o-', color=\"g\")\n",
    "plt.legend(('Train', 'Validation'))\n",
    "plt.xlabel('Lambda user'); plt.ylabel('RMSE');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## !!! Takes long time to run\n",
    "\n",
    "method = 0     # 0-SGD 1-ALS\n",
    "K = 10        ## K-fold cross validation\n",
    "gamma = 0.01\n",
    "num_features = 20   # K in the lecture notes\n",
    "lambda_user = 0.1\n",
    "lambda_item_arr = [0.01, 0.1, 0.5, 1]\n",
    "\n",
    "train_rmse_mean = np.zeros(len(lambda_item_arr))\n",
    "train_rmse_std = np.zeros(len(lambda_item_arr))\n",
    "validation_rmse_mean = np.zeros(len(lambda_item_arr))\n",
    "validation_rmse_std = np.zeros(len(lambda_item_arr))\n",
    "\n",
    "for i, lambda_item in enumerate(lambda_item_arr):\n",
    "    train_rmse_arr = []\n",
    "    validation_rmse_arr = []\n",
    "    \n",
    "    print('Running lambda_item={n}'.format(n=lambda_item))\n",
    "    [train_rmse_arr, validation_rmse_arr] = cross_validation(ratings, K, method, num_items_per_user, \n",
    "                                                             num_users_per_item, min_num_ratings=10)\n",
    "        \n",
    "    train_rmse_mean[i] = np.mean(train_rmse_arr)\n",
    "    train_rmse_std[i] = np.std(train_rmse_arr)\n",
    "    validation_rmse_mean[i] = np.mean(validation_rmse_arr)\n",
    "    validation_rmse_std[i] = np.std(validation_rmse_std)\n",
    "    \n",
    "## Plotting results\n",
    "plt.fill_between(lambda_item_arr, train_rmse_mean - train_rmse_std,\n",
    "                     train_rmse_mean + train_rmse_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(lambda_item_arr, validation_rmse_mean - validation_rmse_std,\n",
    "                     validation_rmse_mean + validation_rmse_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(lambda_item_arr, train_rmse_mean, 'o-', color=\"r\")\n",
    "plt.plot(lambda_item_arr, validation_rmse_mean, 'o-', color=\"g\")\n",
    "plt.legend(('Train', 'Validation'))\n",
    "plt.xlabel('Lambda item'); plt.ylabel('RMSE');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## !!! Takes long time to run\n",
    "\n",
    "method = 0     # 0-SGD\n",
    "K = 10        ## K-fold cross validation\n",
    "gamma_arr = [0.01, 0.1, 1]\n",
    "num_features = 20   # K in the lecture notes\n",
    "lambda_user = 0.1\n",
    "lambda_item = 0.5\n",
    "\n",
    "train_rmse_mean = np.zeros(len(gamma_arr))\n",
    "train_rmse_std = np.zeros(len(gamma_arr))\n",
    "validation_rmse_mean = np.zeros(len(gamma_arr))\n",
    "validation_rmse_std = np.zeros(len(gamma_arr))\n",
    "\n",
    "for i, gamma in enumerate(gamma_arr):\n",
    "    train_rmse_arr = []\n",
    "    validation_rmse_arr = []\n",
    "    \n",
    "    print('Running gamma={n}'.format(n=gamma))\n",
    "    [train_rmse_arr, validation_rmse_arr] = cross_validation(ratings, K, method, num_items_per_user, \n",
    "                                                             num_users_per_item, min_num_ratings=10)\n",
    "        \n",
    "    train_rmse_mean[i] = np.mean(train_rmse_arr)\n",
    "    train_rmse_std[i] = np.std(train_rmse_arr)\n",
    "    validation_rmse_mean[i] = np.mean(validation_rmse_arr)\n",
    "    validation_rmse_std[i] = np.std(validation_rmse_std)\n",
    "    \n",
    "## Plotting results\n",
    "plt.fill_between(gamma_arr, train_rmse_mean - train_rmse_std,\n",
    "                     train_rmse_mean + train_rmse_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(gamma_arr, validation_rmse_mean - validation_rmse_std,\n",
    "                     validation_rmse_mean + validation_rmse_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(gamma_arr, train_rmse_mean, 'o-', color=\"r\")\n",
    "plt.plot(gamma_arr, validation_rmse_mean, 'o-', color=\"g\")\n",
    "plt.legend(('Train', 'Validation'))\n",
    "plt.xlabel('Learning Rate'); plt.ylabel('RMSE');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "#### 1. Compare SGD, ALS with the best set of parameters (based on above results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
