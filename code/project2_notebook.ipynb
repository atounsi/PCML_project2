{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import calculate_mse\n",
    "%load_ext autoreload\n",
    "%autoreload 2\u001c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"../data/data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEbCAYAAABgLnslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncs45l1n/HyRRptq0/AuwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c996dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 8, min # of users per item = 3.\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data and return train and test data. TODO\n",
    "    # NOTE: we only consider users and movies that have more\n",
    "    # than 10 ratings\n",
    "    # generate random indices\n",
    "    train = sp.lil_matrix((len(valid_items), len(valid_users)))\n",
    "    test = sp.lil_matrix((len(valid_items), len(valid_users)))\n",
    "    index_row,index_col = valid_ratings.nonzero()\n",
    "    for i in np.arange(len(index_row)):\n",
    "        # train or test\n",
    "        choice = np.random.choice(a=[1, 2],p=[0.1,0.9])\n",
    "        if(choice == 1):\n",
    "            test[index_row[i],index_col[i]] = valid_ratings[index_row[i],index_col[i]]\n",
    "        else:\n",
    "            train[index_row[i],index_col[i]] = valid_ratings[index_row[i],index_col[i]]\n",
    "    # ***************************************************\n",
    "    #print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    #print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    #print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:1058916\n",
      "Total number of nonzero elements in test data:117957\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train_validation, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)\n",
    "#plot_train_test_data(train_validation, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Matrix factorisation using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "    \n",
    "    # ***************************************************\n",
    "    num_items, num_users = train.shape\n",
    "    user_features = np.random.randint(low=0, high=5, size= (num_features,num_users))\n",
    "    item_features = np.random.randint(low=0, high=5, size=(num_items,num_features))\n",
    "    # ***************************************************\n",
    "    return 1.0*user_features,1.0*item_features\n",
    "\n",
    "def compute_error(data, user_features, item_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    # ***************************************************\n",
    "    real_label = np.array([data[d,n] for (d,n) in nz])\n",
    "    prediction = np.array([(np.dot(item_features[d,:],(user_features[:,n]))) for (d,n) in nz])\n",
    "    rmse = np.sqrt((1/len(nz))*calculate_mse(real_label,prediction))\n",
    "    # ***************************************************\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_SGD(train, test, num_features, lambda_user, lambda_item, gamma):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    # define parameters\n",
    "    #gamma = 0.01\n",
    "    #num_features = 10   # K in the lecture notes\n",
    "    #lambda_user = 0.1\n",
    "    #lambda_item = 0.7\n",
    "    num_epochs = 20     # number of full passes through the train set\n",
    "    #errors = [0]\n",
    "    learning_curve_train = []\n",
    "    learning_curve_test = []\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "\n",
    "    num_items, num_users = train.shape\n",
    "    \n",
    "    #print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        #gamma /= 1.2\n",
    "        \n",
    "        for d, n in nz_train:\n",
    "        # ***************************************************\n",
    "            prediction = item_features[d,:].dot(user_features[:,n])\n",
    "            #gradient\n",
    "            gradient = np.zeros(((num_items + num_users),num_features))\n",
    "            prediction_error = (train[d,n] - prediction)\n",
    "            #print(prediction_error)\n",
    "            #gradient entries for W\n",
    "            gradient[d,:] = -(prediction_error)*(user_features[:,n].T)\n",
    "            #gradient entries for Z\n",
    "            gradient[num_items+n,:] = -(prediction_error)*(item_features[d,:])\n",
    "            \n",
    "            #update\n",
    "            item_features = item_features - gamma*gradient[:num_items,:]\n",
    "            user_features = user_features - gamma*gradient[num_items:,:].T\n",
    "            \n",
    "        train_rmse = compute_error(train, user_features, item_features, nz_train)\n",
    "        # ***************************************************\n",
    "\n",
    "        #print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        learning_curve_train.append(train_rmse)\n",
    "        learning_curve_test.append(compute_error(test, user_features, item_features, nz_test))\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "\n",
    "    test_rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "    #print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    \n",
    "    return train_rmse, test_rmse, user_features, item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    # ***************************************************\n",
    "    num_items,num_users = train.shape\n",
    "    num_features = item_features.shape[1]\n",
    "    user_feature = np.zeros((num_features,num_users))\n",
    "    for user in np.arange(num_users):\n",
    "        nnz_items = nnz_items_per_user[user]\n",
    "        nz_itemindices = nz_user_itemindices[user]\n",
    "        nz_itemfeatures = item_features[nz_itemindices,:]\n",
    "        A = ((nz_itemfeatures.T).dot(nz_itemfeatures)+lambda_user*nnz_items*np.eye(num_features))\n",
    "        train_user = train[nz_itemindices,user].toarray()#[:,0]\n",
    "        b = ((nz_itemfeatures.T).dot(train_user))[:,0]\n",
    "        user_feature[:,user] = np.linalg.solve(A,b)\n",
    "    # ***************************************************\n",
    "    return user_feature\n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    # ***************************************************\n",
    "    num_items,num_users = train.shape\n",
    "    num_features = user_features.shape[0]\n",
    "    item_feature = np.zeros((num_items,num_features))\n",
    "    for item in np.arange(num_items):\n",
    "        nnz_users = nnz_users_per_item[item]\n",
    "        nz_userindices = nz_item_userindices[item]\n",
    "        nz_userfeatures = user_features[:,nz_userindices]\n",
    "        A = ((nz_userfeatures).dot(nz_userfeatures.T)+lambda_item*nnz_users*np.eye(num_features))\n",
    "        train_item = (train[item,nz_userindices].T).toarray()#[:,0]\n",
    "        b = ((nz_userfeatures).dot(train_item))[:,0]\n",
    "        item_feature[item,:] = np.linalg.solve(A,b)\n",
    "    # ***************************************************\n",
    "    return item_feature\n",
    "\n",
    "def init_MF_ALS(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "    \n",
    "    # ***************************************************\n",
    "    num_items, num_users = train.shape\n",
    "    user_mean = np.array(train.sum(axis=0)/train.getnnz(axis=0))\n",
    "    user_features = np.r_[user_mean,np.random.randn(num_features-1,num_users)]\n",
    "    item_mean = np.array(train.sum(axis=1).T/train.getnnz(axis=1)).T\n",
    "    item_features = np.c_[item_mean,np.random.randn(num_items,num_features-1)]\n",
    "    #item_features = np.zeros((num_items,num_features))\n",
    "    # ***************************************************\n",
    "    return 1.0*user_features,1.0*item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import build_index_groups\n",
    "np.seterr(all='raise') \n",
    "\n",
    "def ALS(train, test, num_features, lambda_user, lambda_item):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 10   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    #error_list = [0, 0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF_ALS(train, num_features)\n",
    "    \n",
    "    # ***************************************************\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "    nz_train, nz_row_colindices, nz_col_rowindices = build_index_groups(train)\n",
    "    _,nz_user_itemindices = map(list,zip(*nz_col_rowindices))\n",
    "    nnz_items_per_user = [len(i) for i in nz_user_itemindices]\n",
    "    _,nz_item_userindices = map(list,zip(*nz_row_colindices))\n",
    "    nnz_users_per_item = [len(i) for i in nz_item_userindices]\n",
    "    max_it = 20\n",
    "    \n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "\n",
    "    for it in np.arange(max_it):\n",
    "        user_features = update_user_feature(train, item_features, lambda_user, nnz_items_per_user, nz_user_itemindices)\n",
    "        item_features = update_item_feature(train, user_features, lambda_item, nnz_users_per_item, nz_item_userindices)\n",
    "        \n",
    "        train_rmse = compute_error(train, user_features, item_features, nz_train)\n",
    "        #print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))        \n",
    "        #error_list.append(rmse)\n",
    "        if abs(error_list[-1]-error_list[-2])<stop_criterion:\n",
    "            break\n",
    "\n",
    "    test_rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "    #print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    \n",
    "    return train_rmse, test_rmse, user_features, item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## !!! Takes long time to run\n",
    "\n",
    "method = 0     # 0-SGD 1-ALS\n",
    "K = 10         ## K-fold cross validation\n",
    "gamma = 0.01\n",
    "num_features_arr = [2 10 20 50 100]   # K in the lecture notes\n",
    "lambda_user = 0.1\n",
    "lambda_item = 0.7\n",
    "\n",
    "train_rmse_mean = np.zeros(len(num_features_arr))\n",
    "train_rmse_std = np.zeros(len(num_features_arr))\n",
    "validation_rmse_mean = np.zeros(len(num_features_arr))\n",
    "validation_rmse_std = np.zeros(len(num_features_arr))\n",
    "\n",
    "for i, num_features in enumerate(num_features_arr):\n",
    "    train_rmse_arr = []\n",
    "    validation_rmse_arr = []\n",
    "    \n",
    "    print('Running num_features={n}'.format(n=num_features))\n",
    "    for k in range(K):\n",
    "        print('Running {n}th fold'.format(n=k+1))\n",
    "\n",
    "        ## Splitting data in kth fold\n",
    "        valid_ratings, training, validation = split_data(train, num_items_per_user, num_users_per_item, \n",
    "                                                           min_num_ratings=10, p_test=0.1)\n",
    "        if method == 0:  ## SGD\n",
    "            [train_rmse, validation_rmse, user_feature, item_features] = matrix_factorization_SGD(training,\n",
    "                                                 validation, num_features, lambda_user, lambda_item, gamma) \n",
    "        else:            ## ALS\n",
    "            [train_rmse, validation_rmse, user_feature, item_features] = ALS(training,\n",
    "                                                    validation, num_features, lambda_user, lambda_item) \n",
    "            \n",
    "        train_rmse_arr.append(train_rmse)\n",
    "        validation_rmse_arr.append(validation_rmse)\n",
    "        \n",
    "    ## Calculate mean and standard deviation    \n",
    "    train_rmse_mean[i] = np.mean(train_rmse_arr)\n",
    "    train_rmse_std[i] = np.std(train_rmse_arr)\n",
    "    validation_rmse_mean[i] = np.mean(validation_rmse_arr)\n",
    "    validation_rmse_std[i] = np.std(validation_rmse_std)\n",
    "    \n",
    "## Plotting results\n",
    "plt.fill_between(num_features_arr, train_rmse_mean - train_rmse_std,\n",
    "                     train_rmse_mean + train_rmse_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(num_features_arr, validation_rmse_mean - validation_rmse_std,\n",
    "                     validation_rmse_mean + validation_rmse_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(num_features_arr, train_rmse_mean, 'o-', color=\"r\")\n",
    "plt.plot(num_features_arr, validation_rmse_mean, 'o-', color=\"g\")\n",
    "plt.legend(('Train', 'Validation'))\n",
    "plt.xlabel('Number of features (K)'); plt.ylabel('RMSE');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lambda_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## !!! Takes long time to run\n",
    "\n",
    "method = 0     # 0-SGD 1-ALS\n",
    "K = 10        ## K-fold cross validation\n",
    "gamma = 0.01\n",
    "num_features = 20   # K in the lecture notes\n",
    "lambda_user_arr = [0.01, 0.1, 1, 10]\n",
    "lambda_item = 0.7\n",
    "\n",
    "train_rmse_mean = np.zeros(len(lambda_user_arr))\n",
    "train_rmse_std = np.zeros(len(lambda_user_arr))\n",
    "validation_rmse_mean = np.zeros(len(lambda_user_arr))\n",
    "validation_rmse_std = np.zeros(len(lambda_user_arr))\n",
    "\n",
    "for i, lambda_user in enumerate(lambda_user_arr):\n",
    "    train_rmse_arr = []\n",
    "    validation_rmse_arr = []\n",
    "    \n",
    "    print('Running lambda_user={n}'.format(n=lambda_user))\n",
    "    for k in range(K):\n",
    "        print('Running {n}th fold'.format(n=k+1))\n",
    "\n",
    "        ## Splitting data in kth fold\n",
    "        valid_ratings, training, validation = split_data(train, num_items_per_user, num_users_per_item, \n",
    "                                                           min_num_ratings=10, p_test=0.1)\n",
    "        if method == 0:   ## SGD\n",
    "            [train_rmse, validation_rmse, user_feature, item_features] = matrix_factorization_SGD(training,\n",
    "                                                    validation, num_features, lambda_user, lambda_item, gamma) \n",
    "        else:             ## ALS\n",
    "            [train_rmse, validation_rmse, user_feature, item_features] = ALS(training,\n",
    "                                                    validation, num_features, lambda_user, lambda_item) \n",
    "            \n",
    "        train_rmse_arr.append(train_rmse)\n",
    "        validation_rmse_arr.append(validation_rmse)\n",
    "        \n",
    "    train_rmse_mean[i] = np.mean(train_rmse_arr)\n",
    "    train_rmse_std[i] = np.std(train_rmse_arr)\n",
    "    validation_rmse_mean[i] = np.mean(validation_rmse_arr)\n",
    "    validation_rmse_std[i] = np.std(validation_rmse_std)\n",
    "    \n",
    "## Plotting results\n",
    "plt.fill_between(lambda_user_arr, train_rmse_mean - train_rmse_std,\n",
    "                     train_rmse_mean + train_rmse_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(lambda_user_arr, validation_rmse_mean - validation_rmse_std,\n",
    "                     validation_rmse_mean + validation_rmse_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(lambda_user_arr, train_rmse_mean, 'o-', color=\"r\")\n",
    "plt.plot(lambda_user_arr, validation_rmse_mean, 'o-', color=\"g\")\n",
    "plt.legend(('Train', 'Validation'))\n",
    "plt.xlabel('Lambda user'); plt.ylabel('RMSE');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## !!! Takes long time to run\n",
    "\n",
    "method = 0     # 0-SGD 1-ALS\n",
    "K = 10        ## K-fold cross validation\n",
    "gamma = 0.01\n",
    "num_features = 20   # K in the lecture notes\n",
    "lambda_user = 0.1\n",
    "lambda_item_arr = [0.01, 0.1, 0.5, 1]\n",
    "\n",
    "train_rmse_mean = np.zeros(len(lambda_item_arr))\n",
    "train_rmse_std = np.zeros(len(lambda_item_arr))\n",
    "validation_rmse_mean = np.zeros(len(lambda_item_arr))\n",
    "validation_rmse_std = np.zeros(len(lambda_item_arr))\n",
    "\n",
    "for i, lambda_item in enumerate(lambda_item_arr):\n",
    "    train_rmse_arr = []\n",
    "    validation_rmse_arr = []\n",
    "    \n",
    "    print('Running lambda_item={n}'.format(n=lambda_item))\n",
    "    for k in range(K):\n",
    "        print('Running {n}th fold'.format(n=k+1))\n",
    "\n",
    "        ## Splitting data in kth fold\n",
    "        valid_ratings, training, validation = split_data(train, num_items_per_user, num_users_per_item, \n",
    "                                                           min_num_ratings=10, p_test=0.1)\n",
    "        if method == 0:   ## SGD\n",
    "            [train_rmse, validation_rmse, user_feature, item_features] = matrix_factorization_SGD(training,\n",
    "                                                    validation, num_features, lambda_user, lambda_item, gamma) \n",
    "        else:             ## ALS\n",
    "            [train_rmse, validation_rmse, user_feature, item_features] = ALS(training,\n",
    "                                                    validation, num_features, lambda_user, lambda_item) \n",
    "            \n",
    "        train_rmse_arr.append(train_rmse)\n",
    "        validation_rmse_arr.append(validation_rmse)\n",
    "        \n",
    "    train_rmse_mean[i] = np.mean(train_rmse_arr)\n",
    "    train_rmse_std[i] = np.std(train_rmse_arr)\n",
    "    validation_rmse_mean[i] = np.mean(validation_rmse_arr)\n",
    "    validation_rmse_std[i] = np.std(validation_rmse_std)\n",
    "    \n",
    "## Plotting results\n",
    "plt.fill_between(lambda_item_arr, train_rmse_mean - train_rmse_std,\n",
    "                     train_rmse_mean + train_rmse_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(lambda_item_arr, validation_rmse_mean - validation_rmse_std,\n",
    "                     validation_rmse_mean + validation_rmse_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(lambda_item_arr, train_rmse_mean, 'o-', color=\"r\")\n",
    "plt.plot(lambda_item_arr, validation_rmse_mean, 'o-', color=\"g\")\n",
    "plt.legend(('Train', 'Validation'))\n",
    "plt.xlabel('Lambda item'); plt.ylabel('RMSE');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## !!! Takes long time to run\n",
    "\n",
    "method = 0     # 0-SGD\n",
    "K = 10        ## K-fold cross validation\n",
    "gamma_arr = [0.01 0.1 1]\n",
    "num_features = 20   # K in the lecture notes\n",
    "lambda_user = 0.1\n",
    "lambda_item = 0.5\n",
    "\n",
    "train_rmse_mean = np.zeros(len(gamma_arr))\n",
    "train_rmse_std = np.zeros(len(gamma_arr))\n",
    "validation_rmse_mean = np.zeros(len(gamma_arr))\n",
    "validation_rmse_std = np.zeros(len(gamma_arr))\n",
    "\n",
    "for i, gamma in enumerate(gamma_arr):\n",
    "    train_rmse_arr = []\n",
    "    validation_rmse_arr = []\n",
    "    \n",
    "    print('Running gamma={n}'.format(n=gamma))\n",
    "    for k in range(K):\n",
    "        print('Running {n}th fold'.format(n=k+1))\n",
    "\n",
    "        ## Splitting data in kth fold\n",
    "        valid_ratings, training, validation = split_data(train, num_items_per_user, num_users_per_item, \n",
    "                                                           min_num_ratings=10, p_test=0.1)\n",
    "        if method == 0:   ## SGD\n",
    "            [train_rmse, validation_rmse, user_feature, item_features] = matrix_factorization_SGD(training,\n",
    "                                                    validation, num_features, lambda_user, lambda_item, gamma) \n",
    "        #else:\n",
    "        #    [train_rmse, validation_rmse, user_feature, item_features] = ALS(train,\n",
    "        #                                            validation, num_features, lambda_user, lambda_item) \n",
    "            \n",
    "        train_rmse_arr.append(train_rmse)\n",
    "        validation_rmse_arr.append(validation_rmse)\n",
    "        \n",
    "    train_rmse_mean[i] = np.mean(train_rmse_arr)\n",
    "    train_rmse_std[i] = np.std(train_rmse_arr)\n",
    "    validation_rmse_mean[i] = np.mean(validation_rmse_arr)\n",
    "    validation_rmse_std[i] = np.std(validation_rmse_std)\n",
    "    \n",
    "## Plotting results\n",
    "plt.fill_between(gamma_arr, train_rmse_mean - train_rmse_std,\n",
    "                     train_rmse_mean + train_rmse_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(gamma_arr, validation_rmse_mean - validation_rmse_std,\n",
    "                     validation_rmse_mean + validation_rmse_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(gamma_arr, train_rmse_mean, 'o-', color=\"r\")\n",
    "plt.plot(gamma_arr, validation_rmse_mean, 'o-', color=\"g\")\n",
    "plt.legend(('Train', 'Validation'))\n",
    "plt.xlabel('Learning Rate'); plt.ylabel('RMSE');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "#### 1. Compare SGD, ALS with the best set of parameters (based on above results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
